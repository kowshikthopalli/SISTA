{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74f081cf-ee13-4a33-99f6-9ecf00a71957",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error building extension 'fused': [1/2] /usr/local/cuda/bin/nvcc  -DTORCH_EXTENSION_NAME=fused -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -isystem /home/orion/.virtualenvs/pytorch/lib/python3.8/site-packages/torch/include -isystem /home/orion/.virtualenvs/pytorch/lib/python3.8/site-packages/torch/include/torch/csrc/api/include -isystem /home/orion/.virtualenvs/pytorch/lib/python3.8/site-packages/torch/include/TH -isystem /home/orion/.virtualenvs/pytorch/lib/python3.8/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /usr/include/python3.8 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 --compiler-options '-fPIC' -std=c++14 -c /mnt/be9f66b9-98c5-4089-a134-498b62c8a25d/orion/Projects/llnl/GAN/SISTA/GenerativeAugmentations/op/fused_bias_act_kernel.cu -o fused_bias_act_kernel.cuda.o \nFAILED: fused_bias_act_kernel.cuda.o \n/usr/local/cuda/bin/nvcc  -DTORCH_EXTENSION_NAME=fused -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -isystem /home/orion/.virtualenvs/pytorch/lib/python3.8/site-packages/torch/include -isystem /home/orion/.virtualenvs/pytorch/lib/python3.8/site-packages/torch/include/torch/csrc/api/include -isystem /home/orion/.virtualenvs/pytorch/lib/python3.8/site-packages/torch/include/TH -isystem /home/orion/.virtualenvs/pytorch/lib/python3.8/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /usr/include/python3.8 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 --compiler-options '-fPIC' -std=c++14 -c /mnt/be9f66b9-98c5-4089-a134-498b62c8a25d/orion/Projects/llnl/GAN/SISTA/GenerativeAugmentations/op/fused_bias_act_kernel.cu -o fused_bias_act_kernel.cuda.o \n/usr/local/cuda/bin/nvcc: 3: exec: /usr/lib/nvidia-cuda-toolkit/bin/nvcc: not found\nninja: build stopped: subcommand failed.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m~/.virtualenvs/pytorch/lib/python3.8/site-packages/torch/utils/cpp_extension.py\u001b[0m in \u001b[0;36m_run_ninja_build\u001b[0;34m(build_directory, verbose, error_prefix)\u001b[0m\n\u001b[1;32m   1899\u001b[0m         \u001b[0mstdout_fileno\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1900\u001b[0;31m         subprocess.run(\n\u001b[0m\u001b[1;32m   1901\u001b[0m             \u001b[0mcommand\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/subprocess.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    515\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcheck\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mretcode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m             raise CalledProcessError(retcode, process.args,\n\u001b[0m\u001b[1;32m    517\u001b[0m                                      output=stdout, stderr=stderr)\n",
      "\u001b[0;31mCalledProcessError\u001b[0m: Command '['ninja', '-v']' returned non-zero exit status 1.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1019102/2835574815.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwandb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me4e_projection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprojection\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me4e_projection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/be9f66b9-98c5-4089-a134-498b62c8a25d/orion/Projects/llnl/GAN/SISTA/GenerativeAugmentations/model.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mop\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconv2d_gradfix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfused_act\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFusedLeakyReLU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfused_leaky_relu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupfirdn2d\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mupfirdn2d\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/be9f66b9-98c5-4089-a134-498b62c8a25d/orion/Projects/llnl/GAN/SISTA/GenerativeAugmentations/op/fused_act.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mmodule_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__file__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m fused = load(\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0;34m\"fused\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     sources=[\n",
      "\u001b[0;32m~/.virtualenvs/pytorch/lib/python3.8/site-packages/torch/utils/cpp_extension.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(name, sources, extra_cflags, extra_cuda_cflags, extra_ldflags, extra_include_paths, build_directory, verbose, with_cuda, is_python_module, is_standalone, keep_intermediates)\u001b[0m\n\u001b[1;32m   1282\u001b[0m         ...     verbose=True)\n\u001b[1;32m   1283\u001b[0m     '''\n\u001b[0;32m-> 1284\u001b[0;31m     return _jit_compile(\n\u001b[0m\u001b[1;32m   1285\u001b[0m         \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1286\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0msources\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msources\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0msources\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/pytorch/lib/python3.8/site-packages/torch/utils/cpp_extension.py\u001b[0m in \u001b[0;36m_jit_compile\u001b[0;34m(name, sources, extra_cflags, extra_cuda_cflags, extra_ldflags, extra_include_paths, build_directory, verbose, with_cuda, is_python_module, is_standalone, keep_intermediates)\u001b[0m\n\u001b[1;32m   1506\u001b[0m                         \u001b[0msources\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhipified_sources\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1508\u001b[0;31m                     _write_ninja_file_and_build_library(\n\u001b[0m\u001b[1;32m   1509\u001b[0m                         \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m                         \u001b[0msources\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msources\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/pytorch/lib/python3.8/site-packages/torch/utils/cpp_extension.py\u001b[0m in \u001b[0;36m_write_ninja_file_and_build_library\u001b[0;34m(name, sources, extra_cflags, extra_cuda_cflags, extra_ldflags, extra_include_paths, build_directory, verbose, with_cuda, is_standalone)\u001b[0m\n\u001b[1;32m   1621\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Building extension module {name}...'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1623\u001b[0;31m     _run_ninja_build(\n\u001b[0m\u001b[1;32m   1624\u001b[0m         \u001b[0mbuild_directory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1625\u001b[0m         \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/pytorch/lib/python3.8/site-packages/torch/utils/cpp_extension.py\u001b[0m in \u001b[0;36m_run_ninja_build\u001b[0;34m(build_directory, verbose, error_prefix)\u001b[0m\n\u001b[1;32m   1914\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'output'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# type: ignore[union-attr]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1915\u001b[0m             \u001b[0mmessage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34mf\": {error.output.decode(*SUBPROCESS_DECODE_ARGS)}\"\u001b[0m  \u001b[0;31m# type: ignore[union-attr]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1916\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1917\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error building extension 'fused': [1/2] /usr/local/cuda/bin/nvcc  -DTORCH_EXTENSION_NAME=fused -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -isystem /home/orion/.virtualenvs/pytorch/lib/python3.8/site-packages/torch/include -isystem /home/orion/.virtualenvs/pytorch/lib/python3.8/site-packages/torch/include/torch/csrc/api/include -isystem /home/orion/.virtualenvs/pytorch/lib/python3.8/site-packages/torch/include/TH -isystem /home/orion/.virtualenvs/pytorch/lib/python3.8/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /usr/include/python3.8 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 --compiler-options '-fPIC' -std=c++14 -c /mnt/be9f66b9-98c5-4089-a134-498b62c8a25d/orion/Projects/llnl/GAN/SISTA/GenerativeAugmentations/op/fused_bias_act_kernel.cu -o fused_bias_act_kernel.cuda.o \nFAILED: fused_bias_act_kernel.cuda.o \n/usr/local/cuda/bin/nvcc  -DTORCH_EXTENSION_NAME=fused -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -isystem /home/orion/.virtualenvs/pytorch/lib/python3.8/site-packages/torch/include -isystem /home/orion/.virtualenvs/pytorch/lib/python3.8/site-packages/torch/include/torch/csrc/api/include -isystem /home/orion/.virtualenvs/pytorch/lib/python3.8/site-packages/torch/include/TH -isystem /home/orion/.virtualenvs/pytorch/lib/python3.8/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /usr/include/python3.8 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 --compiler-options '-fPIC' -std=c++14 -c /mnt/be9f66b9-98c5-4089-a134-498b62c8a25d/orion/Projects/llnl/GAN/SISTA/GenerativeAugmentations/op/fused_bias_act_kernel.cu -o fused_bias_act_kernel.cuda.o \n/usr/local/cuda/bin/nvcc: 3: exec: /usr/lib/nvidia-cuda-toolkit/bin/nvcc: not found\nninja: build stopped: subcommand failed.\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import torch\n",
    "torch.backends.cudnn.benchmark = True\n",
    "from torchvision import transforms, utils\n",
    "from torchvision.utils import save_image\n",
    "from util import *\n",
    "from PIL import Image\n",
    "import math\n",
    "import random\n",
    "import os\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "from torch import nn, autograd, optim\n",
    "from torch.nn import functional as F\n",
    "from tqdm import tqdm\n",
    "import wandb\n",
    "from model import *\n",
    "from e4e_projection import projection as e4e_projection\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "try:\n",
    "    import wandb\n",
    "\n",
    "except ImportError:\n",
    "    wandb = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7768b29b-09cc-4a89-9acc-087624d38864",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_latent(paths, device=None):\n",
    "    transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((1024, 1024)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "    ]\n",
    "    )\n",
    "    if type(paths) == list(): paths = [paths]\n",
    "    \n",
    "    imgs, latents = [], []\n",
    "    for path in paths:\n",
    "        assert os.path.exists(path), f\"{path} does not exist!\"\n",
    "            \n",
    "        img = Image.open(path).convert('RGB')\n",
    "        \n",
    "        latent = e4e_projection(img, device=device)\n",
    "        imgs.append(transform(img))\n",
    "        latents.append(latent)\n",
    "    \n",
    "    latents = torch.stack(latents, 0).squeeze(1).to(device)\n",
    "    imgs = torch.stack(imgs, 0).to(device)\n",
    "    \n",
    "    return imgs, latents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71bc85a7-dc43-472f-8252-33fa3a824c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_JoJO(original_generator, discriminator, styleA_img, latents):\n",
    "    \n",
    "    alpha =  0\n",
    "\n",
    "    preserve_color = False\n",
    "    num_iter = 300\n",
    "\n",
    "    # del generatorA, generatorB, trans_func\n",
    "    # to be finetuned generator\n",
    "    generator = deepcopy(original_generator)\n",
    "    \n",
    "    optimizer = optim.Adam(generator.parameters(), lr=2e-3, betas=(0, 0.99))\n",
    "\n",
    "    # Which layers to swap for generating a family of plausible real images -> fake image\n",
    "    if preserve_color:\n",
    "        id_swap = [9,11,15,16,17]\n",
    "    else:\n",
    "        id_swap = list(range(7, original_generator.n_latent))\n",
    "\n",
    "    # remove the comment if wanting to randomize the face image for the pair\n",
    "    if latents == None:\n",
    "        latents = generator.get_latent(\n",
    "            torch.randn([latents.size(0), latents.size(1), latent_dim]).to(device))\n",
    "\n",
    "    pbar = tqdm(range(num_iter))\n",
    "    for idx in pbar:\n",
    "        # Sample a random w from styleGAN latent space\n",
    "        rand_w = original_generator.get_latent(\n",
    "            torch.randn([latents.size(0), latent_dim]).to(device)).unsqueeze(1).repeat(1, original_generator.n_latent, 1)\n",
    "        # Clone the W+ of StyleA obtained from PSP\n",
    "        in_latent = latents.clone()\n",
    "\n",
    "        # Replace the last layers of in_latent+ with transformed rand_w\n",
    "        in_latent[:, id_swap] = alpha*in_latent[:, id_swap] + (1-alpha)*rand_w[:, id_swap]\n",
    "\n",
    "        # Generate styleA\n",
    "        gen_imgA = generator(in_latent, input_is_latent=True)\n",
    "\n",
    "        # Obtain the features for the discriminator\n",
    "        with torch.no_grad():\n",
    "            real_feat_A = discriminator(styleA_img)\n",
    "        fake_feat_A = discriminator(gen_imgA)\n",
    "\n",
    "        # # Compute L1 feature loss of (realA, genA) and (realB, genB)\n",
    "        loss_disc_A = sum([F.l1_loss(a, b) for a, b in zip(real_feat_A, fake_feat_A)])/len(fake_feat_A)\n",
    "\n",
    "        loss = loss_disc_A\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()            \n",
    "        \n",
    "        pbar.set_description(\n",
    "            (f\" loss_disc_A: {loss_disc_A.item():.4f};\")\n",
    "            )\n",
    "    return generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc071566-8787-4f14-9901-a483619529c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_generators(original_generator, discriminator, model_A_path='models/stylegan2-pencil_sketch.pt', model_B_path='models/stylegan2-water_color.pt', model_C_path='models/stylegan2-color_sketch.pt'):\n",
    "\n",
    "    if os.path.exists(model_A_path):\n",
    "        print(f'Loaded {model_A_path}')\n",
    "        ckpt = torch.load(model_A_path, map_location=lambda storage, loc: storage)\n",
    "        generatorA = deepcopy(original_generator)\n",
    "        generatorA.load_state_dict(ckpt[\"g_ema\"], strict=False)\n",
    "    else:\n",
    "        imgs = ['data/style_ref/celebA_ref/sketch_147.jpg']\n",
    "        sketch_ref, sketch_w = get_latent(imgs, device)\n",
    "        generatorA = train_JoJO(original_generator, discriminator, sketch_ref, sketch_w)\n",
    "        torch.save({\"g_ema\": generatorA.state_dict()}, model_A_path)\n",
    "\n",
    "    if os.path.exists(model_B_path):\n",
    "        print(f'Loaded {model_B_path}')\n",
    "        ckpt = torch.load(model_B_path, map_location=lambda storage, loc: storage)\n",
    "        generatorB = deepcopy(original_generator)\n",
    "        generatorB.load_state_dict(ckpt[\"g_ema\"], strict=False)\n",
    "    else:\n",
    "        imgs = ['data/style_ref/watercolor_147.jpg']    \n",
    "        toon_ref, toon_w = get_latent(imgs, device)\n",
    "        generatorB = train_JoJO(original_generator, discriminator, toon_ref, toon_w)\n",
    "        torch.save({\"g_ema\": generatorB.state_dict()}, model_B_path)\n",
    "\n",
    "\n",
    "    if os.path.exists(model_C_path):\n",
    "        print(f'Loaded {model_C_path}')\n",
    "        ckpt = torch.load(model_C_path, map_location=lambda storage, loc: storage)\n",
    "        generatorC = deepcopy(original_generator)\n",
    "        generatorC.load_state_dict(ckpt[\"g_ema\"], strict=False)\n",
    "    else:\n",
    "        imgs = ['data/style_ref/celebA_ref/color_sketch147.jpg']    \n",
    "        toon_ref, toon_w = get_latent(imgs, device)\n",
    "        generatorC = train_JoJO(original_generator, discriminator, toon_ref, toon_w)\n",
    "        torch.save({\"g_ema\": generatorC.state_dict()}, model_C_path)\n",
    "\n",
    "    return generatorA, generatorB, generatorC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8951fb24-15fa-4469-bda8-3c2d6457b7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "    \n",
    "iteration=1000 #\"total training iterations\"\n",
    "batch_size=1 #\"No of pairs each training iteration\"\n",
    "size=1024 #\"image sizes for the model\"\n",
    "latent_dim=512 #\"StyleGAN latent code dim\"\n",
    "\n",
    "StyleGAN_ckpt='models/stylegan2-ffhq-config-f.pt' #\"path to the checkpoints to resume training\","
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955f9618-b302-4a8e-87f0-12cb64bc3700",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load original generator\n",
    "original_generator = Generator(size, latent_dim, 8).to(device)\n",
    "ckpt = torch.load(StyleGAN_ckpt, map_location=lambda storage, loc: storage)\n",
    "original_generator.load_state_dict(ckpt[\"g_ema\"], strict=False)\n",
    "mean_latent = original_generator.mean_latent(10000)\n",
    "\n",
    "# load discriminator for perceptual loss\n",
    "discriminator = Discriminator(size).eval().to(device)\n",
    "ckpt = torch.load(StyleGAN_ckpt, map_location=lambda storage, loc: storage)\n",
    "discriminator.load_state_dict(ckpt[\"d\"], strict=False)\n",
    "discriminator.eval()\n",
    "print(\"Loaded generator and discriminator\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921af347-9dec-45d7-b8ce-dedaf1da45d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "generatorA, generatorB, generatorC = load_generators(original_generator, discriminator)\n",
    "# generatorA, generatorB, generatorC = load_generators(original_generator, discriminator, model_C_path='models/stylegan2-color_sketch.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925ee1bf",
   "metadata": {},
   "source": [
    "## Evaluate the loaded generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2d3bf9-0d02-49d7-bf6d-a71b48ae1633",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_samples = 1\n",
    "\n",
    "z = torch.randn(test_samples, latent_dim, device=device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    generatorA.eval()\n",
    "    generatorB.eval()\n",
    "    generatorC.eval()\n",
    "\n",
    "    true_img = original_generator([z], input_is_latent=False)\n",
    "    # Generate styleA and styleB\n",
    "    gen_imgA = generatorA([z], input_is_latent=False)\n",
    "    gen_imgB = generatorB([z], input_is_latent=False)\n",
    "    gen_imgC = generatorC([z], input_is_latent=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc99d04-34bf-4386-ba61-cc61a50e3297",
   "metadata": {},
   "outputs": [],
   "source": [
    "recon_A = torch.cat([true_img, gen_imgA], 0)\n",
    "recon_A = utils.make_grid(recon_A, normalize=True, range=(-1, 1), nrow=test_samples)\n",
    "display_image(recon_A, title='TrueA, ReconA')\n",
    "\n",
    "recon_B = torch.cat([true_img, gen_imgB], 0)\n",
    "recon_B = utils.make_grid(recon_B, normalize=True, range=(-1, 1), nrow=test_samples)\n",
    "display_image(recon_B, title='TrueB, GenB')\n",
    "\n",
    "recon_C = torch.cat([true_img, gen_imgC], 0)\n",
    "recon_C = utils.make_grid(recon_C, normalize=True, range=(-1, 1), nrow=test_samples)\n",
    "display_image(recon_C, title='TrueB, GenC')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627f2534",
   "metadata": {},
   "source": [
    "## Generate target data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff266178",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(original_generator, generatorA, generatorB, generatorC):\n",
    "\n",
    "    # data_dir = 'data/multi_domain_interpol_gen'\n",
    "    data_dir = '/mnt/e0e0461d-3972-4e84-bf9b-685ecd68ebce/datasets/GAN/multi_domain_interpol_gen_10K'\n",
    "    \n",
    "\n",
    "    os.makedirs(f'{data_dir}/orig/', exist_ok=True)\n",
    "    os.makedirs(f'{data_dir}/z/', exist_ok=True)\n",
    "\n",
    "    os.makedirs(f'{data_dir}/pencil_sketch/', exist_ok=True)\n",
    "    os.makedirs(f'{data_dir}/colorsketch/', exist_ok=True)\n",
    "    os.makedirs(f'{data_dir}/watercolor/', exist_ok=True)\n",
    "\n",
    "    for i in tqdm(range(10000)):\n",
    "        # Sample a random z from styleGAN latent space\n",
    "        z = torch.randn(1, latent_dim, device=device)\n",
    "        # z = torch.load(f'{data_dir}/z/{i}.pt')\n",
    "\n",
    "        with torch.no_grad():\n",
    "            orig_img = original_generator([z], input_is_latent=False)\n",
    "            orig_img = utils.make_grid(orig_img[0], normalize=True, range=(-1, 1))\n",
    "            save_image(orig_img, f'{data_dir}/orig/{i}.png')\n",
    "\n",
    "\n",
    "            dom_A = generatorA([z], input_is_latent=False)\n",
    "            dom_A = utils.make_grid(dom_A[0], normalize=True, range=(-1, 1))\n",
    "            save_image(dom_A, f'{data_dir}/pencil_sketch/{i}.png')\n",
    "\n",
    "\n",
    "            dom_B = generatorB([z], input_is_latent=False)\n",
    "            dom_B = utils.make_grid(dom_B[0], normalize=True, range=(-1, 1))\n",
    "            save_image(dom_B, f'{data_dir}/colorsketch/{i}.png')\n",
    "\n",
    "            dom_C = generatorC([z], input_is_latent=False)\n",
    "            dom_C = utils.make_grid(dom_C[0], normalize=True, range=(-1, 1))\n",
    "            save_image(dom_C, f'{data_dir}/watercolor/{i}.png')\n",
    "            torch.save(z, f'{data_dir}/z/{i}.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0e187a",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_data(original_generator, generatorA, generatorB, generatorC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6fb188",
   "metadata": {},
   "source": [
    "## GAN Interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea56dc14-1663-4a4e-ab22-830375c730d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_interpol = deepcopy(original_generator)\n",
    "        \n",
    "inter_alpha = 0.5\n",
    "for (nameA, paramA), (nameB, paramB), (nameC, paramC) in zip(generatorA.named_parameters(), generatorB.named_parameters(), generator_interpol.named_parameters()):\n",
    "        paramC.data = paramA.data*inter_alpha + (1-inter_alpha)*paramB.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321713eb-59f2-43f1-9279-a260a740f3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    generator_interpol.eval()    \n",
    "    \n",
    "    rand_w = original_generator.get_latent(torch.randn([3, latent_dim]).to(device)).unsqueeze(1).repeat(1, original_generator.n_latent, 1)\n",
    "    # Generate styleA and styleB\n",
    "    gen_imgA = generatorA([z], input_is_latent=False)\n",
    "    gen_imgB = generatorB([z], input_is_latent=False)\n",
    "    \n",
    "    # Generate styleA and styleB\n",
    "    gen_imgC = generator_interpol([z], input_is_latent=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edcc9ed6-918a-4783-aef1-b1b832da3588",
   "metadata": {},
   "outputs": [],
   "source": [
    "recon_A = torch.cat([gen_imgA, gen_imgB, gen_imgC], 0)\n",
    "recon_A = utils.make_grid(recon_A, normalize=True, range=(-1, 1), nrow=test_samples)\n",
    "print(recon_A.shape)\n",
    "display_image(recon_A, title='Sketch GAN, toonGAN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731d5e47-c818-47cd-a753-425a6bdd3255",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_interpol = deepcopy(original_generator)\n",
    "\n",
    "inter_alpha = 0.5\n",
    "z = torch.randn(1, latent_dim, device=device)\n",
    "alphas_img = []\n",
    "for inter_alpha in np.arange(0,1.2,0.1):\n",
    "\n",
    "    for (nameA, paramA), (nameB, paramB), (nameC, paramC) in zip(original_generator.named_parameters(), generatorA.named_parameters(), generator_interpol.named_parameters()):\n",
    "            paramC.data = paramA.data*inter_alpha + (1-inter_alpha)*paramB.data       \n",
    "\n",
    "    n_sample = 3\n",
    "\n",
    "    with torch.no_grad():\n",
    "        generator_interpol.eval()    \n",
    "        # Generate styleA and styleB\n",
    "        gen_imgC = generator_interpol([z], input_is_latent=False)\n",
    "        alphas_img.append(gen_imgC)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6facc808-0d13-414e-9496-0f0b40759ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas_img = torch.cat(alphas_img, 0)\n",
    "alphas_img = utils.make_grid(alphas_img, normalize=True, range=(-1, 1))\n",
    "display_image(alphas_img, title='Sketch GAN, toonGAN')\n",
    "\n",
    "save_image(alphas_img, 'walk.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902a6959",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data_interpol_pairs(original_generator, generatorA, generatorB):\n",
    "\n",
    "    # data_dir = 'data/multi_domain_interpol_gen'\n",
    "    data_dir = '/mnt/e0e0461d-3972-4e84-bf9b-685ecd68ebce/datasets/GAN/multi_domain_interpol_gen'\n",
    "    generatorsA_list = []\n",
    "    for inter_alpha in np.arange(0,1.1,0.1):\n",
    "\n",
    "        generator_interpol = deepcopy(original_generator)\n",
    "        for (nameA, paramA), (nameB, paramB), (nameC, paramC) in zip(original_generator.named_parameters(), generatorA.named_parameters(), generator_interpol.named_parameters()):\n",
    "                paramC.data = paramA.data*inter_alpha + (1-inter_alpha)*paramB.data      \n",
    "\n",
    "        generatorsA_list.append(generator_interpol)\n",
    "\n",
    "    # generatorsB_list = []\n",
    "    # for inter_alpha in np.arange(0,1.2,0.1):\n",
    "\n",
    "    #     generator_interpol = deepcopy(original_generator)\n",
    "    #     for (nameA, paramA), (nameB, paramB), (nameC, paramC) in zip(original_generator.named_parameters(), generatorB.named_parameters(), generator_interpol.named_parameters()):\n",
    "    #             paramC.data = paramA.data*inter_alpha + (1-inter_alpha)*paramB.data      \n",
    "\n",
    "    #     generatorsB_list.append(generator_interpol)\n",
    "    \n",
    "\n",
    "    os.makedirs(f'{data_dir}/orig/', exist_ok=True)\n",
    "    os.makedirs(f'{data_dir}/z/', exist_ok=True)\n",
    "    for i in tqdm(range(1000)):\n",
    "        # Sample a random z from styleGAN latent space\n",
    "        # z = torch.randn(1, latent_dim, device=device)\n",
    "        z = torch.load(f'{data_dir}/z/{i}.pt')\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # orig_img = original_generator([z], input_is_latent=False)\n",
    "            # orig_img = utils.make_grid(orig_img[0], normalize=True, range=(-1, 1))\n",
    "            # save_image(orig_img, f'{data_dir}/orig/{i}.png')\n",
    "            # torch.save(z, f'{data_dir}/z/{i}.pt')\n",
    "            # for j, (generatorStyleA, generatorStyleB) in enumerate(zip(generatorsA_list, generatorsB_list)):\n",
    "            for j, generatorStyleA in enumerate(generatorsA_list):\n",
    "                img_styleA = generatorStyleA([z], input_is_latent=False)\n",
    "                # img_styleB = generatorStyleB([z], input_is_latent=False)\n",
    "            \n",
    "                os.makedirs(f'{data_dir}/pencil_sketch_{j}/', exist_ok=True)\n",
    "                # os.makedirs(f'{data_dir}/watercolor_{j}/', exist_ok=True)\n",
    "                \n",
    "                img_styleA = utils.make_grid(img_styleA[0], normalize=True, range=(-1, 1))\n",
    "                # img_styleB = utils.make_grid(img_styleB[0], normalize=True, range=(-1, 1))\n",
    "                save_image(img_styleA, f'{data_dir}/pencil_sketch_{j}/{i}.png')\n",
    "                # save_image(img_styleB, f'{data_dir}/watercolor_{j}/{i}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36c756a",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_data_interpol_pairs(original_generator, generatorA, generatorB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9210f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = torch.randn(1, latent_dim, device=device)\n",
    "orig_img = original_generator([z], input_is_latent=False)\n",
    "orig_img = utils.make_grid(orig_img, normalize=True, range=(-1, 1))\n",
    "\n",
    "display_image(orig_img, title='Test img')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa5af596",
   "metadata": {},
   "source": [
    "## Random Style Layers weights reverting to original GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0933314b",
   "metadata": {},
   "outputs": [],
   "source": [
    "style_layers = ['convs.6', 'convs.7', 'to_rgbs.3', 'convs.8', 'convs.9', 'to_rgbs.4', 'convs.10', 'convs.11', 'to_rgbs.5',\n",
    "                'convs.12', 'convs.13', 'to_rgbs.6', 'convs.14', 'convs.15', 'to_rgbs.7']\n",
    "\n",
    "mixed_GANs_A, mixed_GANs_B = [], []\n",
    "for _ in range(2):\n",
    "        generatorA_temp = deepcopy(generatorA)\n",
    "        generatorB_temp = deepcopy(generatorB)\n",
    "        for (name_orig, param_orig), (nameA, paramA), (nameB, paramB) in zip(original_generator.named_parameters(), generatorA_temp.named_parameters(),  generatorB_temp.named_parameters()):\n",
    "                coin = random.randint(0,1)\n",
    "                res = False\n",
    "                res = [True for y in style_layers if y in nameA]\n",
    "                if res and coin:\n",
    "                        paramA.data = param_orig.data\n",
    "                        paramB.data = param_orig.data\n",
    "        mixed_GANs_A.append(generatorA_temp)\n",
    "        mixed_GANs_B.append(generatorB_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488522de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rewind_generator(original_generator, generatorA, generatorB):\n",
    "        style_layers = ['convs.6', 'convs.7', 'to_rgbs.3', 'convs.8', 'convs.9', 'to_rgbs.4', 'convs.10', 'convs.11', 'to_rgbs.5',\n",
    "                        'convs.12', 'convs.13', 'to_rgbs.6', 'convs.14', 'convs.15', 'to_rgbs.7']\n",
    "\n",
    "        generatorA_temp = deepcopy(generatorA)\n",
    "        generatorB_temp = deepcopy(generatorB)\n",
    "        for (name_orig, param_orig), (nameA, paramA), (nameB, paramB) in zip(original_generator.named_parameters(), generatorA_temp.named_parameters(),  generatorB_temp.named_parameters()):\n",
    "                # coin = random.randint(0,1)\n",
    "                prob = np.random.rand()\n",
    "                res = False\n",
    "                res = [True for y in style_layers if y in nameA]\n",
    "                if res and (prob < 0.2):\n",
    "                        paramA.data = param_orig.data\n",
    "                        paramB.data = param_orig.data\n",
    "        return generatorA_temp, generatorB_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7fbabbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = torch.randn(1, latent_dim, device=device)\n",
    "true_img = original_generator([z], input_is_latent=False)\n",
    "\n",
    "\n",
    "img_A = generatorA([z], input_is_latent=False)\n",
    "img_B = generatorB([z], input_is_latent=False)\n",
    "\n",
    "imgs_A, imgs_B = [true_img, img_A], [true_img, img_B]\n",
    "for i in range(2):\n",
    "    # Generate styleA and styleB\n",
    "    imgs_A.append(mixed_GANs_A[i]([z], input_is_latent=False))\n",
    "\n",
    "    imgs_B.append(mixed_GANs_B[i]([z], input_is_latent=False))\n",
    "\n",
    "recon_A = torch.cat(imgs_A, 0)\n",
    "recon_A = utils.make_grid(recon_A, normalize=True, range=(-1, 1), nrow=len(imgs_A))\n",
    "display_image(recon_A, title='TrueA, layer mix images')\n",
    "save_image(recon_A, 'mixup_A.png')\n",
    "\n",
    "recon_B = torch.cat(imgs_B, 0)\n",
    "recon_B = utils.make_grid(recon_B, normalize=True, range=(-1, 1), nrow=len(imgs_B))\n",
    "display_image(recon_B, title='TrueB, layer mix images')\n",
    "save_image(recon_B, 'mixup_B.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55fe90b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data_rewinded_pairs(original_generator, generatorA, generatorB):\n",
    "\n",
    "    # data_dir = 'data/multi_domain_interpol_gen'\n",
    "    data_dir = '/mnt/e0e0461d-3972-4e84-bf9b-685ecd68ebce/datasets/GAN/multi_domain_interpol_gen'\n",
    "    \n",
    "\n",
    "    os.makedirs(f'{data_dir}/orig/', exist_ok=True)\n",
    "    os.makedirs(f'{data_dir}/z/', exist_ok=True)\n",
    "    for i in tqdm(range(1000)):\n",
    "        if os.path.exists(f'{data_dir}/z/{i}.pt'):\n",
    "            z = torch.load(f'{data_dir}/z/{i}.pt')\n",
    "        else:\n",
    "            # Sample a random z from styleGAN latent space\n",
    "            # z = torch.randn(1, latent_dim, device=device)\n",
    "            continue\n",
    "\n",
    "        with torch.no_grad():\n",
    "            mixed_GAN_A, mixed_GAN_B = rewind_generator(original_generator, generatorA, generatorB)\n",
    "            # Generate styleA and styleB\n",
    "            img_styleA = mixed_GAN_A([z], input_is_latent=False)\n",
    "\n",
    "            img_styleB = mixed_GAN_B([z], input_is_latent=False)\n",
    "            \n",
    "            os.makedirs(f'{data_dir}/rewind_colorsketch/', exist_ok=True)\n",
    "            # os.makedirs(f'{data_dir}/rewind_watercolor/', exist_ok=True)\n",
    "            \n",
    "            img_styleA = utils.make_grid(img_styleA[0], normalize=True, range=(-1, 1))\n",
    "            img_styleB = utils.make_grid(img_styleB[0], normalize=True, range=(-1, 1))\n",
    "\n",
    "            save_image(img_styleA, f'{data_dir}/rewind_colorsketch/{i}.png')\n",
    "            # save_image(img_styleB, f'{data_dir}/rewind_watercolor/{i}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f4dc9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_data_rewinded_pairs(original_generator, generatorA, generatorB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae81024",
   "metadata": {},
   "source": [
    "## Pruning Zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3381f011",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_samples = 1\n",
    "\n",
    "z = torch.randn(test_samples, latent_dim, device=device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    generatorA.eval()\n",
    "    generatorB.eval()\n",
    "\n",
    "    true_img = original_generator([z], input_is_latent=False)\n",
    "    true_img_zero = original_generator([z], input_is_latent=False, percentile=50, mask_type='zeros')\n",
    "    true_img_random = original_generator([z], input_is_latent=False, percentile=50, mask_type='randn')\n",
    "    # Generate styleA and styleB\n",
    "    gen_imgA_zeros = generatorA([z], input_is_latent=False, percentile=50, mask_type='zeros')\n",
    "    gen_imgA_random = generatorA([z], input_is_latent=False, percentile=50, mask_type='randn')\n",
    "    gen_imgB_zeros = generatorB([z], input_is_latent=False, percentile=50, mask_type='zeros')\n",
    "    gen_imgB_random = generatorB([z], input_is_latent=False, percentile=50, mask_type='randn')\n",
    "    \n",
    "    gen_imgA = generatorA([z], input_is_latent=False)\n",
    "    gen_imgB = generatorB([z], input_is_latent=False)\n",
    "    gen_imgC = generatorC([z], input_is_latent=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59ee0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "recon_T = torch.cat([true_img, true_img_zero, true_img_random], 0)\n",
    "recon_T = utils.make_grid(recon_T, normalize=True, range=(-1, 1), nrow=recon_T.shape[0])\n",
    "display_image(recon_T, title='TrueA, ReconA')\n",
    "save_image(recon_T, 'activation_edit_T.png')\n",
    "\n",
    "recon_A = torch.cat([true_img, gen_imgA, gen_imgA_zeros, gen_imgA_random], 0)\n",
    "recon_A = utils.make_grid(recon_A, normalize=True, range=(-1, 1), nrow=recon_A.shape[0])\n",
    "display_image(recon_A, title='TrueA, ReconA')\n",
    "save_image(recon_A, 'activation_edit_A.png')\n",
    "\n",
    "recon_B = torch.cat([true_img, gen_imgB, gen_imgB_zeros, gen_imgB_random], 0)\n",
    "recon_B = utils.make_grid(recon_B, normalize=True, range=(-1, 1), nrow=recon_B.shape[0])\n",
    "display_image(recon_B, title='TrueB, recon_B')\n",
    "save_image(recon_B, 'activation_edit_B.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e4ca13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data_activation_prune_pairs(original_generator, generatorA, generatorB, generatorC):\n",
    "\n",
    "    # data_dir = 'data/multi_domain_interpol_gen'\n",
    "    data_dir = '/mnt/e0e0461d-3972-4e84-bf9b-685ecd68ebce/datasets/GAN/multi_domain_interpol_gen_10K'\n",
    "    \n",
    "    os.makedirs(f'{data_dir}/orig/', exist_ok=True)\n",
    "    os.makedirs(f'{data_dir}/z/', exist_ok=True)\n",
    "    for i in tqdm(range(10000)):\n",
    "        if os.path.exists(f'{data_dir}/z/{i}.pt'):\n",
    "            z = torch.load(f'{data_dir}/z/{i}.pt')\n",
    "        else:\n",
    "            # Sample a random z from styleGAN latent space\n",
    "            # z = torch.randn(1, latent_dim, device=device)\n",
    "            continue\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for j in range(1):\n",
    "                # Generate styleA and styleB\n",
    "                img_styleA = generatorA([z], input_is_latent=False, percentile=50, mask_type='zeros')\n",
    "                img_styleB = generatorB([z], input_is_latent=False, percentile=50, mask_type='zeros')\n",
    "                img_styleC = generatorC([z], input_is_latent=False, percentile=50, mask_type='zeros')\n",
    "                \n",
    "                os.makedirs(f'{data_dir}/prune_0_pencil_sketch_{j}/', exist_ok=True)\n",
    "                os.makedirs(f'{data_dir}/prune_0_colorsketch_{j}/', exist_ok=True)\n",
    "                os.makedirs(f'{data_dir}/prune_0_watercolor_{j}/', exist_ok=True)\n",
    "                \n",
    "                img_styleA = utils.make_grid(img_styleA[0], normalize=True, range=(-1, 1))\n",
    "                img_styleB = utils.make_grid(img_styleB[0], normalize=True, range=(-1, 1))\n",
    "                img_styleC = utils.make_grid(img_styleC[0], normalize=True, range=(-1, 1))\n",
    "\n",
    "                \n",
    "                save_image(img_styleA, f'{data_dir}/prune_0_pencil_sketch_{j}/{i}.png')\n",
    "                save_image(img_styleB, f'{data_dir}/prune_0_colorsketch_{j}/{i}.png')\n",
    "                save_image(img_styleC, f'{data_dir}/prune_0_watercolor_{j}/{i}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8a8459",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_data_activation_prune_pairs(original_generator, generatorA, generatorB, generatorC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f922a660",
   "metadata": {},
   "source": [
    "## Randconv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea484e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from randconv.networks import get_network\n",
    "from randconv.networks import RandConvModule\n",
    "\n",
    "\n",
    "device = 'cuda'\n",
    "net = get_network('resnet18', num_classes=3, pretrained=True)\n",
    "\n",
    "data_mean = torch.tensor((0.5, 0.5, 0.5)).reshape(3, 1, 1).to(device)\n",
    "data_std = torch.tensor((0.5, 0.5, 0.5)).reshape(3, 1, 1).to(device)\n",
    "\n",
    "image_size = (1024, 1024)\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "def get_random_module(net, data_mean, data_std):\n",
    "    return RandConvModule(net,\n",
    "                          in_channels=3,\n",
    "                          out_channels=3,\n",
    "                          kernel_size=[1,3,5,7],\n",
    "                          mixing=False, # mix the output of rand conv layer with the original input\n",
    "                          identity_prob=0.0, # the probability that the rand conv is a identity map\n",
    "                          rand_bias=False, # add random bias in convolution laye\n",
    "                          distribution='kaiming_normal', # distribution of random sampling\n",
    "                          data_mean=data_mean,\n",
    "                          data_std=data_std,\n",
    "                          clamp_output=False, # clamp value range of randconv outputs to a range (as in original image)\n",
    "                          )\n",
    "rand_module = get_random_module(net, data_mean, data_std)\n",
    "rand_module.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5a3a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open('data/style_ref/celebA_ref/147.jpg')\n",
    "trans_img = transform(img)\n",
    "\n",
    "data_dir = '/mnt/e0e0461d-3972-4e84-bf9b-685ecd68ebce/datasets/GAN/multi_domain_interpol_gen'\n",
    "    \n",
    "for i in range(50):\n",
    "    rand_module.randomize()\n",
    "    source_img = trans_img.clone().to(device)\n",
    "    aug_img = rand_module(source_img)\n",
    "    print(aug_img.shape)\n",
    "    os.makedirs(f'{data_dir}/randconv_ref/', exist_ok=True)\n",
    "    aug_img = utils.make_grid(aug_img, normalize=True, range=(-1, 1))\n",
    "    save_image(aug_img, f'{data_dir}/randconv_ref/{i}.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6afe4e1f",
   "metadata": {},
   "source": [
    "## Pruning Rewind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4c3478",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data_activation_prune_random_pairs(original_generator, generatorA, generatorB, generatorC):\n",
    "\n",
    "    # data_dir = 'data/multi_domain_interpol_gen'\n",
    "    data_dir = '/mnt/e0e0461d-3972-4e84-bf9b-685ecd68ebce/datasets/GAN/multi_domain_interpol_gen_10k'\n",
    "    \n",
    "\n",
    "    os.makedirs(f'{data_dir}/orig/', exist_ok=True)\n",
    "    os.makedirs(f'{data_dir}/z/', exist_ok=True)\n",
    "    for i in tqdm(range(1000)):\n",
    "        if os.path.exists(f'{data_dir}/z/{i}.pt'):\n",
    "            z = torch.load(f'{data_dir}/z/{i}.pt')\n",
    "        else:\n",
    "            # Sample a random z from styleGAN latent space\n",
    "            # z = torch.randn(1, latent_dim, device=device)\n",
    "            continue\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # Generate styleA and styleB\n",
    "            orig_img, orig_activations = original_generator([z], input_is_latent=False, mask_type='rewind')\n",
    "            \n",
    "            img_styleA = generatorA([z], input_is_latent=False, percentile=20, mask_type='rewind', orig_activations=orig_activations)\n",
    "            img_styleB = generatorB([z], input_is_latent=False, percentile=20, mask_type='rewind', orig_activations=orig_activations)\n",
    "            img_styleC = generatorC([z], input_is_latent=False, percentile=20, mask_type='rewind', orig_activations=orig_activations)\n",
    "            \n",
    "            os.makedirs(f'{data_dir}/prune_rewind_pencil_sketch_20/', exist_ok=True)\n",
    "            os.makedirs(f'{data_dir}/prune_rewind_colorsketch_20/', exist_ok=True)\n",
    "            os.makedirs(f'{data_dir}/prune_rewind_watercolor_20/', exist_ok=True)\n",
    "            \n",
    "            img_styleA = utils.make_grid(img_styleA[0], n1ormalize=True, range=(-1, 1))\n",
    "            img_styleB = utils.make_grid(img_styleB[0], normalize=True, range=(-1, 1))\n",
    "            img_styleC = utils.make_grid(img_styleC[0], normalize=True, range=(-1, 1))\n",
    "\n",
    "            save_image(img_styleA, f'{data_dir}/prune_rewind_pencil_sketch_50/{i}.png')\n",
    "            save_image(img_styleB, f'{data_dir}/prune_rewind_colorsketch_50/{i}.png')\n",
    "            save_image(img_styleC, f'{data_dir}/prune_rewind_watercolor_50/{i}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9695191",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_data_activation_prune_random_pairs(original_generator, generatorA, generatorB, generatorC)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "3260c0dafe9f1a95e75231d573ecdcd4e2e3cb6238b8bbda126aa1421e9f826b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
